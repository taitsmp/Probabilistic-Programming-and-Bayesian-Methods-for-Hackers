{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edward\n",
    "\n",
    "I am going to try to translate chapter 2 examples to Edward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AB testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "#set constants\n",
    "p_true = 0.05  # remember, this is unknown.\n",
    "N = 1500\n",
    "\n",
    "# sample N Bernoulli random variables from Ber(0.05).\n",
    "# each random variable has a 0.05 chance of being a 1.\n",
    "# this is the data-generation step\n",
    "occurrences = stats.bernoulli.rvs(p_true, size=N)\n",
    "\n",
    "print(occurrences) # Remember: Python treats True == 1, and False == 0\n",
    "print(np.sum(occurrences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pymc3\n",
    "#include the observations, which are Bernoulli\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "# The parameters are the bounds of the Uniform.\n",
    "with pm.Model() as model:\n",
    "    p   = pm.Uniform('p', lower=0, upper=1)\n",
    "    obs = pm.Bernoulli(\"obs\", p, observed=occurrences)\n",
    "    # To be explained in chapter 3\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(18000, step=step)\n",
    "    burned_trace = trace[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from edward.models import Bernoulli, Uniform, Normal, Empirical\n",
    "from edward.inferences import MetropolisHastings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "p = Uniform(low=0., high=1.) \n",
    "x = Bernoulli(probs=p, sample_shape=1500) #sample shape matched to data array length\n",
    "\n",
    "#not so sure about these...\n",
    "mu = Normal(loc=0.0, scale=1.0)\n",
    "#proposal_mu = Normal(loc=mu, scale=0.5)\n",
    "q = Empirical(tf.Variable(tf.zeros(1500))) \n",
    "\n",
    "#try a different inference algo that I can understand?\n",
    "#easier to try this? http://edwardlib.org/api/ed/HMC\n",
    "#compare to pymc metropolis\n",
    "# http://docs.pymc.io/api/inference.html?#module-pymc3.step_methods.metropolis\n",
    "\n",
    "#for each random variable you need another variable that describes what you \"think\" it's distribution is. \n",
    "#not sure what my proposal vars should be...\n",
    "inference = MetropolisHastings({p: q}, {}, data={x: occurrences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#edward - sample code\n",
    "\n",
    "from edward.models import Beta, Bernoulli, Empirical\n",
    "from edward import Gibbs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "\n",
    "p = Beta(1.0, 1.0)\n",
    "x = Bernoulli(probs=p, sample_shape=10)\n",
    "\n",
    "qp = Empirical(tf.Variable(tf.zeros(500)))\n",
    "inference = Gibbs({p: qp}, data={x: x_data})\n",
    "\n",
    "inference.run(n_iter=250) #run inference (Gibbs sampling)\n",
    "x.sample(10).eval() #get some samples from x. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_edward)",
   "language": "python",
   "name": "conda_edward"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
