{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taitsmp/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/notebooks/shotgun_classification_yolov8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nZv32-ZUiykY",
        "outputId": "2d78f23d-5b74-4007-8249-25296d0fd0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.77\n",
            "  Downloading ultralytics-8.0.77-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (4.67.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.77)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.77) (2.19.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.77) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.77) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.77) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.77) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.77) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.77) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.77) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.77) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->ultralytics==8.0.77) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics==8.0.77) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics==8.0.77) (3.0.2)\n",
            "Downloading ultralytics-8.0.77-py3-none-any.whl (513 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.77\n",
            "Collecting echo1-coco-split\n",
            "  Downloading echo1_coco_split-0.1.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting funcy<2.0,>=1.17 (from echo1-coco-split)\n",
            "  Downloading funcy-1.18-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from echo1-coco-split) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->echo1-coco-split) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->echo1-coco-split) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->echo1-coco-split) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->echo1-coco-split) (3.5.0)\n",
            "Downloading echo1_coco_split-0.1.5-py3-none-any.whl (5.2 kB)\n",
            "Downloading funcy-1.18-py2.py3-none-any.whl (33 kB)\n",
            "Installing collected packages: funcy, echo1-coco-split\n",
            "Successfully installed echo1-coco-split-0.1.5 funcy-1.18\n",
            "Collecting git+https://github.com/taitsmp/coco-to-yolo.git\n",
            "  Cloning https://github.com/taitsmp/coco-to-yolo.git to /tmp/pip-req-build-019lsmrh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/taitsmp/coco-to-yolo.git /tmp/pip-req-build-019lsmrh\n",
            "  Resolved https://github.com/taitsmp/coco-to-yolo.git to commit 4db16cc0886b40f18fdf5f58b748d4f0b56e69f8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from coco-to-yolo==0.1.5) (6.0.2)\n",
            "Building wheels for collected packages: coco-to-yolo\n",
            "  Building wheel for coco-to-yolo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coco-to-yolo: filename=coco_to_yolo-0.1.5-py3-none-any.whl size=17608 sha256=d683668bd715797913c53aa3bd4e7f5feb563ae19e65ef75fb1165f91dacc804\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ahx9pxsy/wheels/0a/64/ca/05b497084c9a4182506c7c844249fd374a032633a71a182e19\n",
            "Successfully built coco-to-yolo\n",
            "Installing collected packages: coco-to-yolo\n",
            "Successfully installed coco-to-yolo-0.1.5\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics==8.0.77\n",
        "%pip install echo1-coco-split\n",
        "%pip install git+https://github.com/taitsmp/coco-to-yolo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CSiSp5jXi7X7"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pg_RtmYmjHYG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.environ['WANDB_MODE'] = 'disabled'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOj_3TLijhBE",
        "outputId": "b8ad56d4-c8d8-4fee-97aa-715b2de09f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtelarson\u001b[0m (\u001b[33mfb-clips\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "wandb_key = userdata.get('wandb_key') #google colab secrets\n",
        "wandb.login(key=wandb_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YpQzefSjj9p",
        "outputId": "8e7f177a-5c32-4061-bab7-2469367999e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxkvyXX1mifK"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "j8GxfjHzj18T",
        "outputId": "5f522c13-2ab5-413d-9636-33b009ef487c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n/content/yolo_dataset\\n├── images/\\n│   ├── train/      # Training images\\n│   └── val/        # Validation images\\n└── labels/\\n    ├── train/      # Training labels (*.txt files)\\n    └── val/        # Validation labels (*.txt files)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "short_name = 'shotgun'\n",
        "project_name = 'project-11' #internal project name related to label studio\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "coco_file = \"shotgun.20241223_071107.coco.json\"\n",
        "img_sz = 448\n",
        "patience=40\n",
        "use_weighted_classes = True #experimental. Review and make sure it does not override augmentation_params, etc.\n",
        "\n",
        "mlops_project_name = f'{short_name}-classification' #used by wandb. Might be used by mlflow\n",
        "model_arch = 'yolov8m-cls'\n",
        "model_name = f'{short_name}_{model_arch}'\n",
        "\n",
        "base_drive_dir = '/content/drive/Othercomputers/My Mac/fb-clips-data-science'\n",
        "model_root_path = f\"{base_drive_dir}/models\"\n",
        "image_root_path = f\"/content/{project_name}/football-videos-pre-snap\"\n",
        "\n",
        "COCO_FILE = f'{base_drive_dir}/annotations/{coco_file}'\n",
        "DATASET_DIR = '/content/dataset'\n",
        "IMAGE_ROOT = '/content/dataset/images'\n",
        "\n",
        "# organization of training data should be...\n",
        "'''\n",
        "/content/dataset/\n",
        "├── images/\n",
        "├── train.json\n",
        "└── val.json\n",
        "'''\n",
        "\n",
        "YOLO_DATASET_DIR = '/content/yolo_dataset'\n",
        "YOLO_IMAGE_ROOT = f'{YOLO_DATASET_DIR}/images'\n",
        "\n",
        "# we then move things into a yolo-friendly dataset directory using coco-to-yolo\n",
        "'''\n",
        "/content/yolo_dataset\n",
        "├── images/\n",
        "│   ├── train/      # Training images\n",
        "│   └── val/        # Validation images\n",
        "└── labels/\n",
        "    ├── train/      # Training labels (*.txt files)\n",
        "    └── val/        # Validation labels (*.txt files)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-5nqYoOlbeX"
      },
      "source": [
        "## Copy Images From Remote Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1bi1QR0FlVd0",
        "outputId": "12ee69c0-514a-40d7-d4b0-cc7f9c6395fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpdating index cache for path `/usr/share/man/man1'. Wait...done.\n",
            "mandb: can't update index cache /var/cache/man/oldlocal/1230: No such file or directory\n",
            "\rUpdating index cache for path `/usr/local/man/man1'. Wait...done.\n"
          ]
        }
      ],
      "source": [
        "## Copy the data\n",
        "# Install rclone\n",
        "!curl -s https://rclone.org/install.sh | sudo bash > /dev/null\n",
        "\n",
        "# Setup rclone config\n",
        "!mkdir -p ~/.config/rclone\n",
        "!cp \"/content/drive/Othercomputers/My Mac/fb-clips-data-science/config/rclone.conf\" ~/.config/rclone/\n",
        "\n",
        "# Create project directory\n",
        "!mkdir -p {IMAGE_ROOT}\n",
        "\n",
        "# Copy data from remote storage\n",
        "!rclone copy r2-ml:fb-clips-ml/{project_name} {IMAGE_ROOT} \\\n",
        "    --checkers=128 \\\n",
        "    --transfers=128 \\\n",
        "    --fast-list \\\n",
        "    --buffer-size=16M \\\n",
        "    --bwlimit=off \\\n",
        "    --log-level=ERROR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_wE8nzg3nMfU",
        "outputId": "c24276c1-4e98-469f-aeb3-35637f430ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11414\n"
          ]
        }
      ],
      "source": [
        "!find {IMAGE_ROOT} -type f | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQXdMmfYoFTc"
      },
      "source": [
        "## Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG_FsDQjoFxk",
        "outputId": "71cc9d60-8518-4e6e-da9b-52bafebefb38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n",
            "Saved 4707 annotations from 4707 images to train.json\n",
            "Saved 1177 annotations from 1177 images to val.json\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd {DATASET_DIR}\n",
        "!coco-split --annotations_file \"{COCO_FILE}\" --valid_name val.json --valid_ratio 0.2 --test_ratio 0.0\n",
        "%cd -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzWkPohJpIxX",
        "outputId": "0f45ce8c-fa3c-4926-b8d0-776352045123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input directory: /content/dataset\n",
            "Output directory: /content/yolo_dataset\n",
            "Images directory: /content/dataset/images\n",
            "Mode: Classification\n",
            "\n",
            "Found split files: ['train', 'val']\n",
            "\n",
            "Processing train split for classification...\n",
            "Split: train\n",
            "  Total images in annotations: 4707\n",
            "  Successfully processed: 4707\n",
            "\n",
            "Processing val split for classification...\n",
            "Split: val\n",
            "  Total images in annotations: 1177\n",
            "  Successfully processed: 1177\n",
            "\n",
            "Conversion complete!\n",
            "Dataset created at: /content/yolo_dataset\n",
            "\n",
            "Final Class Mapping Summary:\n",
            "---------------------------\n",
            "YOLO ID | Original ID | Class Name\n",
            "---------------------------\n",
            "      0 |         19 | no\n",
            "      1 |         24 | yes\n",
            "---------------------------\n"
          ]
        }
      ],
      "source": [
        "!coco_to_yolo {DATASET_DIR} {YOLO_DATASET_DIR} --images-dir {IMAGE_ROOT} --classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNnkY4I-PSq"
      },
      "source": [
        "## Use Weight Classes (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YtVSJEa-T8t",
        "outputId": "26f07740-76e3-4a39-e9b3-ed9d0ba18eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using weigheted classes\n"
          ]
        }
      ],
      "source": [
        "# weighted_dataset.py\n",
        "\n",
        "if use_weighted_classes:\n",
        "    import numpy as np\n",
        "    from ultralytics.yolo.data.dataset import ClassificationDataset\n",
        "    from ultralytics.yolo.data import build\n",
        "\n",
        "    class WeightedClassificationDataset(ClassificationDataset):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "\n",
        "            # Only apply weighting during training\n",
        "            self.train_mode = \"train\" in str(self.root).lower()\n",
        "            if self.train_mode:\n",
        "                self.setup_weighting()\n",
        "\n",
        "        def setup_weighting(self):\n",
        "            \"\"\"Set up class weights for balanced sampling during training.\"\"\"\n",
        "            # Count instances per class\n",
        "            class_counts = np.zeros(len(self.classes))\n",
        "            for _, class_idx, _, _ in self.samples:\n",
        "                class_counts[class_idx] += 1\n",
        "\n",
        "            # Prevent division by zero by setting min count to 1\n",
        "            class_counts = np.maximum(class_counts, 1)\n",
        "\n",
        "            # Calculate inverse weights (fewer samples = higher weight)\n",
        "            self.class_weights = np.sum(class_counts) / (len(self.classes) * class_counts)\n",
        "\n",
        "            # Calculate sample weights based on their class\n",
        "            self.sample_weights = np.array([self.class_weights[idx] for _, idx, _, _ in self.samples])\n",
        "\n",
        "            # Normalize probabilities\n",
        "            self.probabilities = self.sample_weights / np.sum(self.sample_weights)\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            \"\"\"Get item with weighted sampling during training.\"\"\"\n",
        "            if self.train_mode:\n",
        "                # Use weighted sampling only during training\n",
        "                index = np.random.choice(len(self.samples), p=self.probabilities)\n",
        "\n",
        "            # Use parent class to handle all the augmentation and processing\n",
        "            return super().__getitem__(index)\n",
        "\n",
        "    # Apply the patch\n",
        "    build.ClassificationDataset = WeightedClassificationDataset\n",
        "    print(\"using weigheted classes\")\n",
        "else:\n",
        "    print(\"weighted classes turned off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLFlXTue-PvK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO8OTvUf-TSH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwLDLzebqseK"
      },
      "source": [
        "## Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "82-gDanzrB7x"
      },
      "outputs": [],
      "source": [
        "augmentation_params = {\n",
        "        'hsv_h': 0.4,       # Strong hue shift\n",
        "        'hsv_s': 0.6,       # Strong saturation augmentation\n",
        "        'hsv_v': 0.4,       # Moderate value augmentation\n",
        "        'degrees': 3.0,     # Moderate rotation\n",
        "        'translate': 0.1,   # Moderate translation\n",
        "        'scale': 0.1,       # Moderate scaling\n",
        "        'fliplr': 0.45,      # Horizontal flip okay\n",
        "        'mosaic': 0.0,      # No mosaic\n",
        "        'mixup': 0.0,       # No mixup\n",
        "        'copy_paste': 0.0,  # No copy-paste\n",
        "        'perspective': 0.0007, # Slight perspective change\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4lwLIv3gglcl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# count the training examples\n",
        "with open(f'{DATASET_DIR}/train.json') as f:\n",
        "    tji = json.load(f)\n",
        "    tss = len(tji['images'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGIaFkaRqxfC"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-jlZyIjeIyJ",
        "outputId": "58b1df98-18d2-4829-bc89-effce3f396f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "736\n"
          ]
        }
      ],
      "source": [
        "print(img_sz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "bsPrzRs9qvjD",
        "outputId": "3310962d-f65e-4445-b05d-6447143ac626"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-cls.pt to yolov8m-cls.pt...\n",
            "100%|██████████| 32.7M/32.7M [00:00<00:00, 57.3MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n",
            "New https://pypi.org/project/ultralytics/8.3.53 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.77 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/content/yolo_dataset, epochs=200, patience=40, batch=16, imgsz=448, save=True, save_period=12, cache=False, device=None, workers=8, project=shotgun-classification, name=shotgun_yolov8m-cls_balanced, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.4, hsv_s=0.6, hsv_v=0.4, degrees=3.0, translate=0.1, scale=0.1, shear=0.0, perspective=0.0007, flipud=0.0, fliplr=0.45, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=shotgun-classification/shotgun_yolov8m-cls_balanced\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
            "  7                  -1  1   2655744  ultralytics.nn.modules.Conv                  [384, 768, 3, 2]              \n",
            "  8                  -1  2   7084032  ultralytics.nn.modules.C2f                   [768, 768, 2, True]           \n",
            "  9                  -1  1    988162  ultralytics.nn.modules.Classify              [768, 2]                      \n",
            "YOLOv8m-cls summary: 141 layers, 15774898 parameters, 15774898 gradients, 41.9 GFLOPs\n",
            "Transferred 228/230 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir shotgun-classification/shotgun_yolov8m-cls_balanced', view at http://localhost:6006/\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241223_213912-b3eakvd4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fb-clips/shotgun-classification/runs/b3eakvd4' target=\"_blank\">shotgun_yolov8m-cls_balanced</a></strong> to <a href='https://wandb.ai/fb-clips/shotgun-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fb-clips/shotgun-classification' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fb-clips/shotgun-classification/runs/b3eakvd4' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification/runs/b3eakvd4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 112MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py:636: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(True):\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py:216: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, size=(448, 448), scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1, mask_interpolation=0), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(0.0, 0.0)), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0, normalization='standard'), ToTensorV2(p=1.0, transpose_mask=False)\n",
            "Image sizes 448 train, 448 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mshotgun-classification/shotgun_yolov8m-cls_balanced\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "  0%|          | 0/287 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(self.amp):\n",
            "      1/200      2.47G      0.174         10        448: 100%|██████████| 287/287 [00:30<00:00,  9.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.17it/s]\n",
            "                   all      0.498          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      2/200      2.73G     0.1728         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.607          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      3/200      2.62G     0.1721         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.26it/s]\n",
            "                   all      0.553          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      4/200      2.64G     0.1724         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.76it/s]\n",
            "                   all      0.545          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      5/200      2.51G     0.1713         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.627          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      6/200      2.62G     0.1708         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.24it/s]\n",
            "                   all      0.547          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      7/200      2.62G     0.1698         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.631          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      8/200      2.67G     0.1701         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.22it/s]\n",
            "                   all      0.567          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      9/200      2.54G     0.1691         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.38it/s]\n",
            "                   all      0.624          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     10/200      2.62G     0.1686         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.517          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     11/200       2.5G     0.1684         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.589          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     12/200      2.62G     0.1678         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.582          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     13/200      2.62G     0.1654         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all        0.6          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     14/200      2.62G      0.166         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.616          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     15/200      2.64G     0.1652         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.644          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     16/200      2.53G     0.1669         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.617          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     17/200      2.62G     0.1642         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.639          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     18/200       2.5G     0.1642         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.609          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     19/200      2.53G     0.1663         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.42it/s]\n",
            "                   all       0.61          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     20/200      2.63G     0.1623         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.07it/s]\n",
            "                   all      0.643          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     21/200      2.65G     0.1643         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.85it/s]\n",
            "                   all      0.623          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     22/200      2.65G     0.1604         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.13it/s]\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     23/200      2.65G     0.1609         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.13it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.26it/s]\n",
            "                   all      0.629          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     24/200      2.63G     0.1617         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.673          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     25/200      2.62G     0.1602         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.31it/s]\n",
            "                   all      0.638          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     26/200      2.53G     0.1591         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.32it/s]\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     27/200      2.61G     0.1574         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.87it/s]\n",
            "                   all      0.702          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     28/200      2.62G     0.1575         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.653          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     29/200      2.51G     0.1558         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.664          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     30/200      2.61G     0.1596         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.666          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     31/200      2.65G     0.1557         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all       0.71          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     32/200      2.62G     0.1537         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.85it/s]\n",
            "                   all      0.713          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     33/200      2.67G      0.154         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.694          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     34/200       2.6G     0.1541         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.671          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     35/200      2.62G     0.1527         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.686          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     36/200      2.63G     0.1536         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.698          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     37/200      2.62G     0.1542         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.88it/s]\n",
            "                   all      0.714          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     38/200      2.61G     0.1534         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.681          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     39/200      2.64G     0.1509         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.35it/s]\n",
            "                   all      0.696          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     40/200      2.63G     0.1497         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.687          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     41/200      2.51G     0.1516         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.74it/s]\n",
            "                   all      0.698          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     42/200       2.5G     0.1474         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.26it/s]\n",
            "                   all      0.651          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     43/200      2.61G     0.1523         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.35it/s]\n",
            "                   all       0.71          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     44/200      2.63G     0.1475         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.739          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     45/200      2.62G     0.1469         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.702          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     46/200      2.54G     0.1483         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.735          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     47/200      2.64G     0.1486         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.63it/s]\n",
            "                   all      0.673          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     48/200      2.62G     0.1474         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.737          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     49/200       2.5G     0.1475         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.709          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     50/200       2.5G     0.1456         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.636          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     51/200      2.62G     0.1451         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.755          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     52/200      2.63G     0.1429         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.741          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     53/200      2.62G     0.1447         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.726          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     54/200      2.49G     0.1445         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.725          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     55/200      2.62G     0.1455         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.35it/s]\n",
            "                   all      0.728          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     56/200      2.62G     0.1458         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.729          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     57/200      2.62G     0.1421         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.743          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     58/200      2.61G     0.1383         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.13it/s]\n",
            "                   all      0.735          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     59/200      2.61G     0.1395         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all      0.721          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     60/200      2.62G     0.1405         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     61/200      2.63G     0.1443         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.758          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     62/200      2.61G      0.139         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.741          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     63/200      2.61G     0.1356         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.746          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     64/200      2.63G     0.1351         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.35it/s]\n",
            "                   all      0.752          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     65/200      2.62G     0.1356         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.72it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.756          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     66/200      2.49G     0.1359         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.67it/s]\n",
            "                   all      0.759          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     67/200      2.61G     0.1345         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.764          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     68/200      2.62G     0.1351         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.21it/s]\n",
            "                   all      0.752          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     69/200      2.61G     0.1328         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.05it/s]\n",
            "                   all      0.775          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     70/200      2.62G     0.1338         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.18it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     71/200      2.61G     0.1327         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all       0.77          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     72/200      2.63G     0.1302         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.745          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     73/200      2.62G     0.1337         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.758          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     74/200      2.49G     0.1289         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.96it/s]\n",
            "                   all      0.789          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     75/200      2.61G     0.1335         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.776          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     76/200      2.62G     0.1288         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.73it/s]\n",
            "                   all      0.788          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     77/200      2.61G      0.127         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.27it/s]\n",
            "                   all      0.786          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     78/200      2.62G     0.1305         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all      0.763          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     79/200      2.61G     0.1306         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.20it/s]\n",
            "                   all      0.788          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     80/200      2.63G     0.1282         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.88it/s]\n",
            "                   all      0.763          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     81/200      2.62G      0.128         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.07it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.38it/s]\n",
            "                   all       0.79          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     82/200      2.49G     0.1269         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.782          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     83/200      2.61G     0.1261         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     84/200      2.62G     0.1261         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.782          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     85/200      2.61G     0.1267         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.34it/s]\n",
            "                   all      0.797          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     86/200      2.62G     0.1224         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.20it/s]\n",
            "                   all      0.796          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     87/200      2.61G     0.1205         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.791          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     88/200      2.63G     0.1207         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.53it/s]\n",
            "                   all      0.801          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     89/200      2.62G     0.1209         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.794          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     90/200      2.49G      0.124         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.787          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     91/200      2.61G     0.1226         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.801          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     92/200      2.62G     0.1209         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     93/200      2.61G     0.1228         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.792          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     94/200      2.62G     0.1201         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.801          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     95/200      2.61G     0.1166         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.791          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     96/200      2.63G     0.1211         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.08it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.29it/s]\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     97/200      2.62G     0.1202         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all       0.79          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     98/200      2.49G     0.1139         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.802          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "     99/200      2.61G     0.1134         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.66it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all       0.79          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    100/200      2.62G     0.1171         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.31it/s]\n",
            "                   all      0.794          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    101/200      2.61G     0.1171         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.99it/s]\n",
            "                   all      0.796          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    102/200      2.62G      0.116         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    103/200      2.61G     0.1168         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.808          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    104/200      2.63G     0.1139         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.89it/s]\n",
            "                   all      0.794          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    105/200      2.62G     0.1136         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.784          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    106/200      2.49G     0.1144         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.813          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    107/200      2.61G     0.1078         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.32it/s]\n",
            "                   all      0.807          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    108/200      2.62G     0.1147         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.814          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    109/200      2.61G     0.1138         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.813          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    110/200      2.62G      0.108         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.08it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.807          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    111/200      2.61G     0.1104         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.817          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    112/200      2.63G     0.1061         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.62it/s]\n",
            "                   all      0.808          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    113/200      2.62G     0.1096         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.814          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    114/200      2.49G      0.112         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.814          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    115/200      2.61G     0.1074         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.32it/s]\n",
            "                   all      0.807          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    116/200      2.62G     0.1077         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.35it/s]\n",
            "                   all      0.818          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    117/200      2.61G     0.1076         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.808          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    118/200      2.62G     0.1102         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.38it/s]\n",
            "                   all      0.821          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    119/200      2.61G     0.1065         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.817          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    120/200      2.63G     0.1034         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.75it/s]\n",
            "                   all      0.818          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    121/200      2.62G     0.1047         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.38it/s]\n",
            "                   all      0.818          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    122/200      2.49G     0.1004         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.818          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    123/200      2.61G     0.1046         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.99it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    124/200      2.62G     0.1002         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.825          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    125/200      2.61G        0.1         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.827          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    126/200      2.62G    0.09626         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all      0.829          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    127/200      2.61G     0.1024         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.829          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    128/200      2.63G    0.09963         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.07it/s]\n",
            "                   all      0.829          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    129/200      2.62G    0.09821         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.827          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    130/200      2.49G     0.1004         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.45it/s]\n",
            "                   all      0.831          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    131/200      2.61G    0.09668         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.38it/s]\n",
            "                   all      0.831          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    132/200      2.62G     0.1004         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.828          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    133/200      2.61G    0.09569         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.825          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    134/200      2.62G     0.0967         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.826          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    135/200      2.61G    0.09664         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.35it/s]\n",
            "                   all      0.832          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    136/200      2.63G    0.09265         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.65it/s]\n",
            "                   all      0.827          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    137/200      2.62G    0.09467         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.825          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    138/200      2.49G    0.09695         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.07it/s]\n",
            "                   all      0.825          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    139/200      2.61G    0.09496         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.833          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    140/200      2.62G    0.09162         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.828          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    141/200      2.61G    0.09286         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.831          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    142/200      2.62G    0.09226         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.832          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    143/200      2.61G    0.09147         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.825          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    144/200      2.63G    0.09495         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.12it/s]\n",
            "                   all      0.828          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    145/200      2.62G    0.09211         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.838          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    146/200      2.49G    0.08811         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.07it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.848          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    147/200      2.61G    0.09053         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.25it/s]\n",
            "                   all      0.851          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    148/200      2.62G    0.08569         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.08it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.63it/s]\n",
            "                   all      0.845          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    149/200      2.61G    0.08783         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.74it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.849          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    150/200      2.62G    0.08873         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.25it/s]\n",
            "                   all      0.844          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    151/200      2.61G     0.0885         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.843          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    152/200      2.63G    0.08632         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.07it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.72it/s]\n",
            "                   all      0.846          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    153/200      2.62G     0.0872         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.844          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    154/200      2.49G    0.08539         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.848          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    155/200      2.61G    0.08741         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    156/200      2.62G    0.08129         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.82it/s]\n",
            "                   all      0.848          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    157/200      2.61G    0.08329         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.90it/s]\n",
            "                   all      0.845          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    158/200      2.62G    0.08308         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.24it/s]\n",
            "                   all      0.847          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    159/200      2.61G    0.08175         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.847          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    160/200      2.63G    0.08277         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.78it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.34it/s]\n",
            "                   all      0.844          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    161/200      2.62G    0.08181         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.78it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all      0.844          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    162/200      2.49G    0.07938         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.98it/s]\n",
            "                   all      0.848          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    163/200      2.61G    0.08012         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.27it/s]\n",
            "                   all      0.845          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    164/200      2.62G    0.07694         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.25it/s]\n",
            "                   all      0.847          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    165/200      2.61G    0.07548         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.841          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    166/200      2.62G    0.07954         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.50it/s]\n",
            "                   all      0.843          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    167/200      2.61G    0.07925         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.848          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    168/200      2.63G    0.07932         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.847          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    169/200      2.62G    0.07522         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all       0.85          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    170/200      2.49G    0.07727         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all       0.85          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    171/200      2.61G    0.07061         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.04it/s]\n",
            "                   all      0.851          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    172/200      2.62G    0.07439         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.29it/s]\n",
            "                   all      0.853          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    173/200      2.61G    0.07034         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.854          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    174/200      2.62G     0.0678         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all       0.85          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    175/200      2.61G    0.07392         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.79it/s]\n",
            "                   all      0.854          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    176/200      2.63G    0.07381         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.855          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    177/200      2.62G    0.07189         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.44it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    178/200      2.49G    0.07098         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.31it/s]\n",
            "                   all      0.855          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    179/200      2.61G    0.06813         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.89it/s]\n",
            "                   all      0.856          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    180/200      2.62G    0.06775         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all       0.86          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    181/200      2.61G     0.0699         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.43it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    182/200      2.62G    0.06412         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.47it/s]\n",
            "                   all      0.862          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    183/200      2.61G    0.06746         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    184/200      2.63G    0.06578         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.864          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    185/200      2.62G    0.06402         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.47it/s]\n",
            "                   all      0.865          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    186/200      2.49G    0.06453         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.862          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    187/200      2.61G    0.06341         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.36it/s]\n",
            "                   all      0.865          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    188/200      2.62G    0.06275         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n",
            "                   all      0.866          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    189/200      2.61G    0.06275         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.89it/s]\n",
            "                   all      0.867          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    190/200      2.62G    0.06172         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.60it/s]\n",
            "                   all      0.866          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    191/200      2.61G      0.059         10        448: 100%|██████████| 287/287 [00:23<00:00, 11.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.52it/s]\n",
            "                   all      0.866          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    192/200      2.63G    0.05386         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.41it/s]\n",
            "                   all      0.864          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    193/200      2.62G    0.05982         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.63it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    194/200      2.49G    0.05942         10        448: 100%|██████████| 287/287 [00:23<00:00, 12.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.37it/s]\n",
            "                   all      0.865          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    195/200      2.61G    0.05443         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.18it/s]\n",
            "                   all      0.864          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    196/200      2.62G    0.05626         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.34it/s]\n",
            "                   all      0.867          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    197/200      2.61G    0.05764         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    198/200      2.62G    0.05464         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  7.52it/s]\n",
            "                   all      0.865          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    199/200      2.61G    0.05426         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.46it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "    200/200      2.63G    0.05313         10        448: 100%|██████████| 287/287 [00:24<00:00, 11.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:02<00:00,  8.40it/s]\n",
            "                   all      0.863          1\n",
            "\n",
            "200 epochs completed in 1.537 hours.\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/utils/torch_utils.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from shotgun-classification/shotgun_yolov8m-cls_balanced/weights/last.pt, 31.7MB\n",
            "Optimizer stripped from shotgun-classification/shotgun_yolov8m-cls_balanced/weights/best.pt, 31.7MB\n",
            "Results saved to \u001b[1mshotgun-classification/shotgun_yolov8m-cls_balanced\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>lr/pg1</td><td>█████▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>lr/pg2</td><td>███▇▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>metrics/accuracy_top1</td><td>▁▃▁▂▂▃▃▅▅▄▆▅▆▅▆▆▆▇▇▆▇▆▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>metrics/accuracy_top5</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed(ms)</td><td>▁</td></tr><tr><td>train/loss</td><td>███████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▂▂▂▁</td></tr><tr><td>val/loss</td><td>██▇▇█▇▇▆▆▆▅▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0002</td></tr><tr><td>lr/pg1</td><td>0.0002</td></tr><tr><td>lr/pg2</td><td>0.0002</td></tr><tr><td>metrics/accuracy_top1</td><td>0.86328</td></tr><tr><td>metrics/accuracy_top5</td><td>1</td></tr><tr><td>model/GFLOPs</td><td>41.893</td></tr><tr><td>model/parameters</td><td>15774898</td></tr><tr><td>model/speed(ms)</td><td>1.704</td></tr><tr><td>train/loss</td><td>0.05313</td></tr><tr><td>val/loss</td><td>0.42704</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">shotgun_yolov8m-cls_balanced</strong> at: <a href='https://wandb.ai/fb-clips/shotgun-classification/runs/b3eakvd4' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification/runs/b3eakvd4</a><br> View project at: <a href='https://wandb.ai/fb-clips/shotgun-classification' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241223_213912-b3eakvd4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(f'{model_arch}.pt')\n",
        "\n",
        "results = model.train(\n",
        "    data=f'{YOLO_DATASET_DIR}',\n",
        "    epochs=epochs,\n",
        "    imgsz=img_sz,\n",
        "    batch=batch_size,\n",
        "    **augmentation_params,\n",
        "    task=\"classify\",\n",
        "    name=model_name + (\"_balanced\" if use_weighted_classes else \"\"),\n",
        "    #wandb params below\n",
        "    project=mlops_project_name,\n",
        "    save_period=12,\n",
        "    patience=patience,\n",
        "    resume=False # you probably don't want to resume a run b/c training is fast. change this if you do.\n",
        ")\n",
        "\n",
        "#trying to save some extra params here.\n",
        "wandb.config.update({\n",
        "    'weighted_training': use_weighted_classes,\n",
        "    'coco_file': coco_file,\n",
        "    'training_set_size': tss,\n",
        "})\n",
        "\n",
        "# explicitly finish\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "Cd8PZijBeWdq",
        "outputId": "51fe5dbf-3360-4449-8f91-e446ca3ac709"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█▅▁▁▁</td></tr><tr><td>lr/pg1</td><td>▁▅███</td></tr><tr><td>lr/pg2</td><td>▁▅███</td></tr><tr><td>metrics/accuracy_top1</td><td>▁█▅▆</td></tr><tr><td>metrics/accuracy_top5</td><td>▁▁▁▁</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed(ms)</td><td>▁</td></tr><tr><td>train/loss</td><td>██▁▅▁</td></tr><tr><td>val/loss</td><td>▅▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00985</td></tr><tr><td>lr/pg1</td><td>0.00985</td></tr><tr><td>lr/pg2</td><td>0.00985</td></tr><tr><td>metrics/accuracy_top1</td><td>0.56578</td></tr><tr><td>metrics/accuracy_top5</td><td>1</td></tr><tr><td>model/GFLOPs</td><td>41.893</td></tr><tr><td>model/parameters</td><td>15774898</td></tr><tr><td>model/speed(ms)</td><td>0.737</td></tr><tr><td>train/loss</td><td>0.1724</td></tr><tr><td>val/loss</td><td>0.65437</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">shotgun_yolov8m-cls_balanced</strong> at: <a href='https://wandb.ai/fb-clips/shotgun-classification/runs/m1yfqouc' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification/runs/m1yfqouc</a><br> View project at: <a href='https://wandb.ai/fb-clips/shotgun-classification' target=\"_blank\">https://wandb.ai/fb-clips/shotgun-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241223_122033-m1yfqouc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#run this if you cancelled\n",
        "\n",
        "if wandb.run:\n",
        "      #trying to save some extra params here.\n",
        "    wandb.config.update({\n",
        "        'weighted_training': use_weighted_classes,\n",
        "        'coco_file': coco_file,\n",
        "        'training_set_size': tss,\n",
        "    })\n",
        "\n",
        "    # explicitly finish\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3uHPdN_wCSs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlBoFMaH-KEo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sCQj_hxwHB3"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fFM3Evv2rSUL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "date_match = re.search(r'at-(\\d{4}-\\d{2}-\\d{2})', coco_file)\n",
        "date_mtch2 = re.search(r'-(\\d{4}\\d{2}\\d{2})_(\\d+)', coco_file)\n",
        "if date_match:\n",
        "    # Convert the matched date string to datetime and reformat\n",
        "    date_suf = datetime.strptime(date_match.group(1), '%Y-%m-%d').strftime('%Y%m%d')\n",
        "    model_fullname = f\"{model_name}-{date_suf}.pt\"\n",
        "elif date_mtch2:\n",
        "    # Convert the matched date string to datetime and reformat\n",
        "    date_suf = date_mtch2.group(1)\n",
        "    extra_suf = date_mtch2.group(2)\n",
        "    model_fullname = f\"{model_name}-{date_suf}_{extra_suf}.pt\"\n",
        "else:\n",
        "    # Fallback to current date if pattern not found\n",
        "    date_suf = datetime.now().strftime('%Y%m%d')\n",
        "    model_fullname = f\"{model_name}-{date_suf}.pt\"\n",
        "\n",
        "best_model_path = str(model.trainer.best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t_KfevFSG_Vn",
        "outputId": "754cd1fe-e04c-46e6-841d-ebb7521b9d4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shotgun-classification/shotgun_yolov8m-cls_balanced/weights/best.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K8B5eVUOwLON"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def copy_with_versioning(source_path, dest_path):\n",
        "    \"\"\"\n",
        "    Copy a file to the destination path. If a file with the same name exists,\n",
        "    append a version number (e.g., .2, .3) before the file extension.\n",
        "    \"\"\"\n",
        "    base, ext = os.path.splitext(dest_path)\n",
        "    version = 1\n",
        "\n",
        "    while os.path.exists(dest_path):\n",
        "        version += 1\n",
        "        if version > 9:\n",
        "            raise Exception(\"Exceeded single digit version limits\")\n",
        "        dest_path = f\"{base}.{version}{ext}\"\n",
        "\n",
        "    shutil.copy(source_path, dest_path)\n",
        "    return dest_path\n",
        "\n",
        "\n",
        "# Example usage\n",
        "source_path = best_model_path  # Path to the source file\n",
        "dest_path = f\"{model_root_path}/{model_fullname}\"  # Destination path\n",
        "\n",
        "gm_loc = copy_with_versioning(source_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "vb-cJGr4zvmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b397937-c476-403c-9b0a-3feeb5b2f14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copied model to f/content/drive/Othercomputers/My Mac/fb-clips-data-science/models/shotgun_yolov8m-cls-20241223.2.pt\n"
          ]
        }
      ],
      "source": [
        "print(f'copied model to f{gm_loc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF4q_yttwQCM"
      },
      "source": [
        "## Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOBwFEO6wOTV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def get_last_run_folder(base_path=f'/content/{mlops_project_name}/{model_name}'):\n",
        "    # Get the parent directory of the provided path\n",
        "    parent_dir = os.path.dirname(base_path)\n",
        "\n",
        "    # Extract the base pattern from the provided base_path\n",
        "    base_pattern = os.path.basename(base_path)\n",
        "    base_regex = re.escape(base_pattern) + r'\\d*$'\n",
        "\n",
        "    # Get all subdirectories in the parent directory\n",
        "    folders = [\n",
        "        d for d in os.listdir(parent_dir)\n",
        "        if os.path.isdir(os.path.join(parent_dir, d)) and re.match(base_regex, d)\n",
        "    ]\n",
        "\n",
        "    if folders:\n",
        "        # Sort numerically by trailing numbers and take the last one\n",
        "        return sorted(\n",
        "            folders,\n",
        "            key=lambda x: int(re.findall(r'\\d+$', x)[0]) if re.findall(r'\\d+$', x) else 0\n",
        "        )[-1]\n",
        "\n",
        "    # If no folders found, return None\n",
        "    return None\n",
        "\n",
        "train_folder = get_last_run_folder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uptZ39d13yFH",
        "outputId": "6f87c21d-31fd-4044-c052-d682e246aa95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'snap_yolov8m-cls'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: remove me.\n",
        "train_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_TlCCrKwUMh"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Image, display, HTML\n",
        "\n",
        "\n",
        "def embed_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        encoded_string = base64.b64encode(image_file.read()).decode()\n",
        "    return f\"\"\"\n",
        "    <div>\n",
        "        <img\n",
        "            src=\"data:image/jpeg;base64,{encoded_string}\"\n",
        "            style=\"max-width: 800px\"\n",
        "        />\n",
        "    </div>\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp6Hn5L1wqX2"
      },
      "outputs": [],
      "source": [
        "HTML(embed_image(f'/content/{mlops_project_name}/{train_folder}/confusion_matrix.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMs54O9Fpv1v6szp6jLuCGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}